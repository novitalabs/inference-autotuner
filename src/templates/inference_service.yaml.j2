---
apiVersion: v1
kind: Namespace
metadata:
  name: {{ namespace }}
---
apiVersion: ome.io/v1beta1
kind: InferenceService
metadata:
  name: {{ isvc_name }}
  namespace: {{ namespace }}
  labels:
    autotuner.io/task: "{{ task_name }}"
    autotuner.io/experiment-id: "{{ experiment_id }}"
spec:
  model:
    name: {{ model_name }}
  runtime:
    name: {{ runtime_name }}
    apiGroup: ome.io
    kind: ClusterServingRuntime
  engine:
    minReplicas: 1
    maxReplicas: 1
    runner:
      args:
        - --tp-size={{ params['tp-size'] }}{% if params.get('mem-frac') %}
        - --mem-frac={{ params['mem-frac'] }}{% endif %}{% if params.get('max-total-tokens') %}
        - --max-total-tokens={{ params['max-total-tokens'] }}{% endif %}{% if params.get('schedule-policy') %}
        - --schedule-policy={{ params['schedule-policy'] }}{% endif %}
      resources:
        limits:
          nvidia.com/gpu: {{ params['tp-size'] }}
        requests:
          nvidia.com/gpu: {{ params['tp-size'] }}
