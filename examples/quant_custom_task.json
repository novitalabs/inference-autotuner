{
  "task_name": "custom-quantization",
  "model": {
    "id_or_path": "meta-llama/Llama-3.2-1B-Instruct",
    "namespace": "autotuner"
  },
  "base_runtime": "sglang",
  "runtime_image_tag": "v0.5.2-cu126",
  "quant_config": {
    "gemm_dtype": "fp8",
    "kvcache_dtype": "fp8_e5m2",
    "attention_dtype": "fp8",
    "moe_dtype": "auto"
  },
  "parameters": {
    "tp-size": [1, 2],
    "mem-fraction-static": [0.85]
  },
  "optimization": {
    "strategy": "grid_search",
    "objective": "maximize_throughput",
    "max_iterations": 5
  },
  "benchmark": {
    "task": "text-to-text",
    "model_name": "Llama-3.2-1B-Instruct",
    "model_tokenizer": "meta-llama/Llama-3.2-1B-Instruct",
    "traffic_scenarios": ["D(100,100)"],
    "num_concurrency": [8],
    "additional_params": {
      "temperature": 0.0
    }
  }
}
