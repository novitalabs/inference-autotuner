{
  "task_name": "bayesian-optimization-example",
  "description": "Example task using Bayesian optimization to find optimal parameters",
  "model": {
    "id_or_path": "llama-3-2-1b-instruct",
    "namespace": "autotuner"
  },
  "base_runtime": "sglang",
  "runtime_image_tag": "v0.5.2-cu126",
  "parameters": {
    "tensor-parallel-size": [1, 2, 4],
    "mem-fraction-static": {
      "type": "continuous",
      "low": 0.75,
      "high": 0.95
    },
    "max-total-tokens": {
      "type": "integer",
      "low": 4096,
      "high": 16384
    },
    "schedule-policy": ["lpm", "fcfs"],
    "enable-mixed-chunk": [true, false]
  },
  "optimization": {
    "strategy": "bayesian",
    "objective": "minimize_latency",
    "max_iterations": 20,
    "n_initial_random": 5,
    "timeout_per_iteration": 600
  },
  "benchmark": {
    "task": "text-to-text",
    "model_name": "Llama-3.2-1B-Instruct",
    "model_tokenizer": "meta-llama/Llama-3.2-1B-Instruct",
    "traffic_scenarios": ["D(100,100)"],
    "num_concurrency": [4],
    "additional_params": {
      "temperature": 0.0,
      "max_tokens": 256
    }
  }
}
